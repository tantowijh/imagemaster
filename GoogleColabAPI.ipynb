{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tantowijh/imagerestoration/blob/main/GoogleColabAPI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title __1. Install all the Requirements__\n",
        "#@markdown ⬅ Run this cell to install all the requirements.\n",
        "!pip install diffusers transformers accelerate scipy safetensors &> /dev/null\n",
        "\n",
        "!pip install git+https://github.com/sberbank-ai/Real-ESRGAN.git &> /dev/null\n",
        "!pip install py-real-esrgan &> /dev/null\n",
        "\n",
        "!pip install pyngrok &> /dev/null"
      ],
      "metadata": {
        "id": "juqrpf_yttjb",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title __2. Import Libraries and Load Models__\n",
        "#@markdown ⬅ Run this cell to import all the libraries and load the models.\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from diffusers import AutoPipelineForInpainting\n",
        "import torch\n",
        "from RealESRGAN import RealESRGAN\n",
        "\n",
        "# Load the Real-ESRGAN model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "enhance_pipe = RealESRGAN(device, scale=4)\n",
        "enhance_pipe.load_weights('weights/RealESRGAN_x4.pth', download=True)\n",
        "\n",
        "# Load Inpainting Model\n",
        "inpaint_model = \"diffusers/stable-diffusion-xl-1.0-inpainting-0.1\"\n",
        "inpaint_pipe = AutoPipelineForInpainting.from_pretrained(inpaint_model, torch_dtype=torch.float16, variant=\"fp16\")\n",
        "inpaint_pipe = inpaint_pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "y8hSr953aF0D",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title __3. Initialize the Flask App__\n",
        "#@markdown ⬅ Run this cell to initialize the Flask app, then run the following steps.\n",
        "\n",
        "from flask import Flask, request, send_file, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def home():\n",
        "    return 'Hello, World!'\n",
        "\n",
        "@app.route('/enhance', methods=['POST'])\n",
        "def enhance():\n",
        "  try:\n",
        "    # Get the image from the request\n",
        "    image_data = request.files['image'].read()\n",
        "\n",
        "    # Load the image from the request\n",
        "    image = Image.open(BytesIO(image_data)).convert('RGB')\n",
        "\n",
        "    # Perform the upscaling using Real-ESRGAN\n",
        "    sr_image = enhance_pipe.predict(image)\n",
        "\n",
        "    # Save the upscaled image to a BytesIO buffer\n",
        "    buffered = BytesIO()\n",
        "    sr_image.save(buffered, format=\"PNG\")\n",
        "    buffered.seek(0)\n",
        "\n",
        "    return send_file(buffered, mimetype='image/png', as_attachment=True, download_name='enhanced_image.png')\n",
        "\n",
        "  except Exception as e:\n",
        "    return jsonify({'error': str(e)}), 500\n",
        "\n",
        "@app.route('/restore', methods=['POST'])\n",
        "def restore():\n",
        "  try:\n",
        "    # Get the image, mask, and prompt from the request\n",
        "    image_data = request.files['image'].read()\n",
        "    mask_data = request.files['mask'].read()\n",
        "    prompt = request.form['prompt']\n",
        "\n",
        "    # Get optional parameters from the request\n",
        "    guidance_scale = float(request.form.get('guidance_scale', 8.0))\n",
        "    num_inference_steps = int(request.form.get('num_inference_steps', 20))\n",
        "    strength = float(request.form.get('strength', 0.99))\n",
        "    seed = int(request.form.get('seed', 0))\n",
        "\n",
        "    generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "\n",
        "    # Load the image and mask from the request\n",
        "    image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
        "    mask = Image.open(BytesIO(mask_data)).convert(\"L\")  # Convert mask to grayscale\n",
        "\n",
        "    # Perform the inpainting using the Stable Diffusion model\n",
        "    restored_image = inpaint_pipe(\n",
        "        prompt=prompt,\n",
        "        image=image,\n",
        "        mask_image=mask,\n",
        "        guidance_scale=guidance_scale,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        strength=strength,\n",
        "        generator=generator,\n",
        "    ).images[0]\n",
        "\n",
        "    # Ensure the restored image is the same size as the original\n",
        "    restored_image = restored_image.resize(image.size, Image.LANCZOS)\n",
        "\n",
        "    # Save the restored image to a BytesIO buffer\n",
        "    buffered = BytesIO()\n",
        "    restored_image.save(buffered, format=\"PNG\")\n",
        "    buffered.seek(0)\n",
        "\n",
        "    return send_file(buffered, mimetype='image/png', as_attachment=True, download_name='restored_image.png')\n",
        "\n",
        "  except Exception as e:\n",
        "    return jsonify({'error': str(e)}), 500\n"
      ],
      "metadata": {
        "id": "BWJyKPxHP6Sj",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title __4. Run the Flask App into Public URL__\n",
        "#@markdown ⬅ Run this cell to run Flask, then retrieve the URL and enter it into the configuration page.\n",
        "\n",
        "#@markdown __Choose a Service for the Public URL__\n",
        "\n",
        "#@markdown We recommend using **ngrok** to obtain your public URL, as **Serveo** is not always available (it may be down).\n",
        "\n",
        "\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "import re\n",
        "\n",
        "remote_port = 80\n",
        "local_port = 5000\n",
        "service = \"ngrok\" # @param [\"ngrok\",\"serveo\"]\n",
        "ngrok.kill()\n",
        "\n",
        "def run_app():\n",
        "  app.run(host='0.0.0.0', port=local_port)\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown __Obtain Your ngrok Token__\n",
        "#@markdown\n",
        "#@markdown Please obtain your ngrok auth token from the official ngrok website at\n",
        "#@markdown [ngrok authtoken](https://dashboard.ngrok.com/get-started/your-authtoken).\n",
        "#@markdown > **Note:** Entering your ngrok token is mandatory only if you choose the ngrok service. If you select Serveo, you can skip this step.\n",
        "\n",
        "#@markdown Please put the token you received below:\n",
        "if service == \"ngrok\":\n",
        "  authtoken = \"\" #@param {type:\"string\"}\n",
        "  ngrok.set_auth_token(authtoken)\n",
        "\n",
        "  ngrok_run = ngrok.connect(local_port).public_url\n",
        "  print(f\"Ngrok public URL: {ngrok_run}\\n\")\n",
        "  run_app()\n",
        "\n",
        "else:\n",
        "  # Command to run in the background, using the defined port variables\n",
        "  command = [\"ssh\", \"-o\", \"StrictHostKeyChecking=no\", \"-R\", f\"{remote_port}:localhost:{local_port}\", \"serveo.net\"]\n",
        "\n",
        "  # Start the process\n",
        "  process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "  # Allow some time for the connection to establish and the URL to be printed\n",
        "  time.sleep(5)\n",
        "\n",
        "  # Read the output and search for the URL\n",
        "  output, errors = process.communicate(timeout=5)\n",
        "\n",
        "  # Use regex to find the URL in the output\n",
        "  url_match = re.search(r'(https?://[^\\s]+)', output)\n",
        "  if url_match:\n",
        "      serveo_url = url_match.group(0)\n",
        "      print(f'Serveo public URL: {serveo_url}\\n')\n",
        "      run_app()\n",
        "  else:\n",
        "      print('No URL! The service may be down.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Eu9zNEInsp6S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}